# Hugging Face Datasets with Human Judgments

Hugging Face hosts several datasets containing human judgments used for evaluating and fine-tuning language models, especially regarding safety, helpfulness, truthfulness, and quality.

---

### Key Datasets with Human Judgment Data

-   **lmsys/mt_bench_human_judgments**: This dataset contains human ratings for model responses on the MT-Bench, a popular benchmark for evaluating chatbot performance. It includes human judgments on the quality and helpfulness of responses generated by various language models.

-   **sorry-bench/sorry-bench-human-judgment-202406**: This dataset provides over 7.2K human safety judgments for LLM responses to potentially unsafe instructions. The human annotations classify responses as either fulfilling or refusing the unsafe prompts, which is valuable for training and evaluating automated safety evaluators.
